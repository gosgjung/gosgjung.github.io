---
title: 주요 업무 경험들
author: Soon Good Jung
date: 2022-12-06
category: Jekyll
layout: post
---


# 논리적인 접근을 통한 안정적인 트래픽 처리 경험

> 웨이커, 증권데이터 처리 서버 개발
>
> - 미국주식에는 1만 2천개 이상의 주식이 존재하고, 이 주식 데이터의 거래데이터는 1ms에 200건의 거래데이터가 발생합니다.
> - 이 데이터를 모두 발생 즉시마다 처리하려면 부하를 피할 수 없습니다. 같은 성격의 데이터를 실세계에 존재하는 킷값으로 고유한 작업 ID를 구성해 고유한 작업 ID를 가지도록 했고, 이 작업 ID를 기반으로 같은 작업 ID에 속하는 거래데이터일 경우 그루핑을 하는 방식의 최적화 작업들을 수행했습니다.


<br>


메시징과 비동기/스레드 풀 프로그래밍을 효율적으로 구성해 트래픽을 안정적으로 처리해본 경험이 있습니다. 단순히 메시징 만을 사용해 프로젝트를 진행하는 것은 어렵지 않습니다. 메시징에 최적화된 구조로 메시징 인프라에 장애 또는 부하를 주지 않도록 소프트웨어를 구성하는 것은 조금은 수고를 해야 하는 작업입니다. 애플리케이션의 각 부분을 용도 별로 구분해서 인프라에 장애, 부하를 주지 않도록 각각의 역할을 병렬, 동시성 개념을 통해 해결했습니다.

이렇게 문제를 풀어내기 위해 미국 주식 데이터가 1ms 에 몇 건의 데이터가 오는지, 500건 단위의 데이터 BULK INSERT 작업에는 평균적으로 몇 ms가 소요되는지, 캐시 서버를 이용한 자료구조에 데이터를 put/evict 하는 데에는 몇 ns 의 시간이 소요되는 지를 일일이 모두 파악해 insert, MQ Push 스레드 작업들의 스케쥴링 주기를 결정하는 과정을 거쳤습니다.

그리고 이 작업들의 중복을 최대한 줄이면서 작업의 건수를 줄이기 위해 캐시 자료구조를 최적화를 했고 이것을 통해 스레드의 호출을 지속적으로 줄여나가면서 성능이 최적화되도록 이끌어낸 경험이 있습니다.


# Backend/Frontend 개발 경험

> 누리플렉스, 에너지 모니터링 시스템
>
> - 장비현황, 장비 통계
>   - 차트, 그리드, 검색조건, SQL이 복잡하게 구성된 페이지였습니다.
> - 에너지 모니터링 시스템 대시보드
>   - Map 을 표현하는 시각화 라이브러리와 SQL 을 활용해 전체 사업장들의 에너지 사용현황, 외기 온도 등을 조망할 수 있는 대시보드를 구현한 경험이 있습니다.
>   - 백엔드 개발은 한번 정해진 요구사항으로 계속 진행되었지만, 프론트 엔드 개발을 하면서 클라이언트의 불분명한 요구사항을 직접 파악해야 하는 것이 가장 힘들었던 경험이었습니다.
>   - 대시보드 특성상 당사자들간 서로 조율되지 않은 요구사항들이 정리되지 않고 자주 발생하는 것으로 인해 의미없는 작업을 여러번 반복한 적도 있었고, 이 과정을 거치면서 클라이언트 개발자들의 고충을 진심으로 느낄수 있던 계기 였습니다.
>   - 이런 업무 특성으로 인해 Naver Map, Daum Map, D3 Map, Leaflet.js 를 차례로 적용하는 과정을 거치면서 요구사항을 만족시키는 과정을 겪었습니다.


<br>


장비현황, 통계 페이지는 차트와 그리드 검색조건, 그리고 SQL이 복잡하게 구성된 페이지였습니다. 사용자의 입력을 3번째 클릭까지 순서대로 기억했다가 최근 세번째 까지 클릭한 지표까지의 차트를 동적으로 페이지에 렌더링하거나, 지표를 클릭할 때마다 나타나는 차트를 동적으로 생성해야 하는 요구사항, 이 외에도 RACK과 같이 부모 노드가 존재하는 장비에 대해 동적으로 차트/그리드를 표현하는 등 프론트엔드 측에서도 여러 모로 손이 많이 가는 작업들을 수행해본 경험들이 있었습니다.

에너지 사업장들을 통합적으로 모니터링하는 Map 기반의 대시보드 구현시에는 백엔드 작업도 많았지만, 유달리 프론트 엔드측에서 자주 발생하는 단발성 요구사항들을 지속적으로 반영해야 했는데, 그 과정에서 Naver맵, Daum 맵, Leaflet, D3 기반으로 구성한 대시보드를 차례대로 구현해 SK E&S 측의 고객들에게 보여줘야만 하는 상황이 있었습니다. 

CJ PCC 신재생 에너지 센터 에너지모니터링 시스템의 운영/유지보수 업무를 담당하면서는 Angular.js 기반의 프로젝트를 유지보수하는 업무를 맡아왔습니다. 주된 업무는 ActiveMQ API의 데이터가 부정확하게 전달되는 경우에 대한 프론트 엔드 측에서의 처리, E2E 테스트 코드 구현/검증, Active MQ API 서버의 트래픽 처리가 끊겼을 때의 타임아웃을 통한 커넥션 종료 및 주기적인 재접속 시도 로직 구현 등의 업무를 수행했습니다.


# 업무적으로 비협조적인 상황에서의 문제해결 경험

> 웨이커, 증권데이터 처리 서버 개발
>
> - 레피니티브라고 벤더사에서 제공하는 거래 데이터 API 에서 제공하는 거래 데이터는 거래시각/거래가격 등의 필드들을 모호하게 보내주는 경우가 많습니다.
> - 예를 들면 미국주식에서는 거래시각이라는 필드명이 `SALTIM_MS` 라고 하는 필드로 전달해주지만, 특정 ETF 는 `SALTIM` 이라는 필드로만 내려오는 경우도 있습니다. 이런 현상은 미국주식 외에도 ETF,채권, 중국주식, 지수 등의 데이터에도 무분별하게 발생했습니다.
> - 이런 현상을 해결하려면, 개발용도의 메시지 큐를 개설하는 작업이 필요했는데, 그 당시의 인프라팀의 데브옵스 엔지니어들은 근무 태만이 심하기도 했고, 개발 용도의 메시지 큐 개설에 대해 전혀 이해를 못하는 상황이라 3개월 정도 설득을 거쳤고, 그 전 까지는 로컬 환경에서 `raw` 데이터를 명시적으로 검증할 수 있는 환경을 마련해야 했습니다.
> - 이와 같은 현상을 해결하기 위해 매핑 룰을 객체지향적으로 구성해, 모호하게 내려오는 필드명을 매칭 시키는 소프트웨어 로직을 작성하는 작업도 수행했고, 이것을 검증하기 위해 로컬 테스트 환경을 구축했습니다.
> - 쉽게 설명하면, 실제 라이브 데이터의 로그를 추출하고, 추출한 로그에서 json 덤프를 만들고, 이 json 덤프를 통해 필드 매핑을 테스트하는 구조의 테스트 환경이었습니다.


<br>


증권 데이터 서버 개발 시에는 인프라 팀의 데브옵스 관계자들을 설득하는데에 꽤 어려움을 겪었습니다. 증권 데이터의 트래픽 데이터를 중계해주는 개발용도의 메시지 큐 서버를 구성해야 했는데, 인프라 팀 구성원을 설득하는 데에 3개월 이상을 설득하고 나서야 개발 용도의 메시지 큐를 개설할 수 있었습니다.

이런 이유로 개발 서버 구성 전 까지는 개발용도의 메시징 서버 없이 소스코드 레벨에서 TCP/IP 통신 시에 주고 받는 raw 데이터의 각 필드 매핑에 대한 검증 작업이 필요했습니다. 이 외에도 증권 데이터 API 의 raw 데이터 매핑(거래시각, 시가/고자/종가/저가 등의 필드)들도 직접 모두 일일이 파악해야 했습니다.

예를 들면 시간 외 거래 데이터를 파악하기 위해서는 시간 외 데이터가 보내주는 거래시각, 가격데이터가 필요합니다. 증권데이터는 이 필드 명이 모호하게 전달되고 개발자 문서를 제공하지 않기에 직접 API 사용자가 필드를 파악해서 매핑하는 것이 증권 데이터 개발에서의 핵심적인 업무입니다.

이런 문제를 해결하기 위해 직접 상용데이터의 로그를 남기는 로직과 이 로그를 json 으로 변환하는 로직을 만들었고, 이 json 데이터를 기반으로 데이터 매핑을 검증하는 테스트 코드를 구현해, 배포시에 직접 파악한 raw 데이터의 필드 매핑이 올바른지 검증할 수 있도록 테스트 환경을 구축했었습니다.

이와 같은 문제는 시간 외 거래 뿐만이 아니라, ETF, 채권, 환율, 지수 등 각 데이터마다 제각각 이었기에 소프트웨어적으로도 매핑을 하는 룰 역할의 클래스를 객체지향적으로 설계하는 것부터 시작해 RAW 데이터를 꼼꼼하게 파악헤 테스트 케이스로 남겨두어 소스코드 레벨에서 명세화 하는 작업이 중요했습니다.

일을 하다보면, 비협조적으로 나오는 유관 부서도 있고, 상황이 여의치 않게 돌아가지 않았고 해결이 안될 것 같은 경우가 있을 수 있는 것 같습니다. 위의 경우가 그런 경우였지만, 포기하지 않고 문제를 해결하기 위해 하나 씩 파악하기 위해 노력해 나갔었고 그 당시에는 인적인 스트레스를 강하게 받아왔는데 돌아보면 긍정적으로 잘 이겨낸 경험이라고 생각합니다.


# API 개발, 서버 개발 경험

작성 중...

# Database

작성 중...